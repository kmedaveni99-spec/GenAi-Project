{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(6898) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (2.3.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(7064) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/37rs6y8d6sxfjyvthxb_rj3h0000gn/T/ipykernel_3175/2878865163.py:9: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  vectordb=FAISS.from_documents(documents,HuggingFaceEmbeddings())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x14200f890>, search_kwargs={})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,HuggingFaceEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Created a retrievel tool to search info related to langsmith\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv Tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x13aefa0c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13b41d950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x13aefa200>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x13b41d950>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "from langchain.agents import create_agent\n",
    "agent=create_agent(llm,tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=<langgraph.graph.state.CompiledStateGraph object at 0x14204d7b0>, input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/keerthanamedaveni/Desktop/GenAi-Project/.venv/lib/python3.13/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x13aefa0c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x14200f890>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x13aefa200>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x14200f890>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}, id='049776d1-0a29-4343-bf35-0a2436930374'), HumanMessage(content='Tell me about LangSmith', additional_kwargs={}, response_metadata={}, id='2abfd57b-e033-48f5-89d7-6e3c3fcc8f4e'), HumanMessage(content='', additional_kwargs={}, response_metadata={}, id='4da283ca-770c-4f5f-8c1e-17bce0bb90a5'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 213, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CbZTEELdHsPR5AgUPisLFpdPcjlVi', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--385f1c32-3794-418d-a9b0-00f172138b97-0', tool_calls=[{'name': 'langsmith_search', 'args': {'query': 'LangSmith'}, 'id': 'call_NdpO5f7D7DrDZcl925P5MQXv', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 16, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='LangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance. For more information, see the Trust Center.\\n\\u200bWorkflow\\nLangSmith combines observability, evaluation, deployment, and platform setup in one integrated workflow—from local development to production.\\n\\nLangSmith docs - Docs by LangChainSkip to main contentDocs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentAgent BuilderPlatform setupOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APIAPI reference for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAccess control & AuthenticationScalability & resilienceFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\\nIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\\n\\nIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\\nLangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\\nlangchain and langgraph.\\nPrototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\\nLangGraph Platform is now LangSmith Deployment. For more information, check out the Changelog.\\n\\u200bGet started\\nCreate an accountSign up at smith.langchain.com (no credit card required).\\nYou can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\\nCopy the key and save it securely.\\nOnce your account and API key are ready, choose a quickstart to begin building with LangSmith:\\n\\nCopy the key and save it securely.\\nOnce your account and API key are ready, choose a quickstart to begin building with LangSmith:\\nObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as Agent Servers, ready to scale in production.Deploy your agentsPlatform setupUse LangSmith in managed cloud, in a self-hosted environment, or hybrid to match your infrastructure and compliance needs.Choose how to set up LangSmithPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with Studio', name='langsmith_search', id='c57584d0-5820-48c1-b648-2a57793baa50', tool_call_id='call_NdpO5f7D7DrDZcl925P5MQXv'), AIMessage(content='LangSmith is a platform designed for developing, debugging, and deploying large language model (LLM) applications. It provides an integrated workflow that combines observability, evaluation, deployment, and platform setup—from local development to production. Key features of LangSmith include:\\n\\n1. **Data Security and Compliance**: LangSmith adheres to high standards of data security and privacy, being compliant with HIPAA, SOC 2 Type 2, and GDPR.\\n\\n2. **Integrated Workflow**: It allows developers to trace requests, evaluate outputs, test prompts, and manage deployments all in one place. This integration helps in building more reliable AI systems.\\n\\n3. **Framework Agnostic**: LangSmith can be used independently or alongside LangChain’s open-source libraries, which offers flexibility in development.\\n\\n4. **Monitoring and Evaluation**: The platform provides tools for integrated monitoring and evaluation, allowing developers to prototype applications locally and scale them to production efficiently.\\n\\n5. **Flexibility in Deployment**: Users can deploy their applications as Agent Servers and choose to use LangSmith in a managed cloud environment, self-hosted setting, or a hybrid model that meets their infrastructure and compliance requirements.\\n\\n6. **Prompt Testing and Development Tools**: LangSmith includes tools for testing prompts with versioning and collaboration features, as well as a visual interface (Studio) for designing and refining applications.\\n\\n7. **Getting Started**: Users can easily create an account, generate an API key, and start building with quickstart guides provided on the platform.\\n\\nOverall, LangSmith aims to simplify the complexities of developing AI applications while ensuring high standards of security and reliability.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 327, 'prompt_tokens': 792, 'total_tokens': 1119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CbZTGDmA3x3xllrfpqVh3KolWaONS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c7072354-0f82-4bbd-b339-564991c2ea5b-0', usage_metadata={'input_tokens': 792, 'output_tokens': 327, 'total_tokens': 1119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "agent_executor = (prompt.partial(agent_scratchpad=[\"\"]) | agent)\n",
    "res = agent_executor.invoke({\"input\": \"Tell me about LangSmith\"})\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"messages\"][5].type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform designed for developing, debugging, and deploying large language model (LLM) applications. It provides an integrated workflow that combines observability, evaluation, deployment, and platform setup—from local development to production. Key features of LangSmith include:\\n\\n1. **Data Security and Compliance**: LangSmith adheres to high standards of data security and privacy, being compliant with HIPAA, SOC 2 Type 2, and GDPR.\\n\\n2. **Integrated Workflow**: It allows developers to trace requests, evaluate outputs, test prompts, and manage deployments all in one place. This integration helps in building more reliable AI systems.\\n\\n3. **Framework Agnostic**: LangSmith can be used independently or alongside LangChain’s open-source libraries, which offers flexibility in development.\\n\\n4. **Monitoring and Evaluation**: The platform provides tools for integrated monitoring and evaluation, allowing developers to prototype applications locally and scale them to production efficiently.\\n\\n5. **Flexibility in Deployment**: Users can deploy their applications as Agent Servers and choose to use LangSmith in a managed cloud environment, self-hosted setting, or a hybrid model that meets their infrastructure and compliance requirements.\\n\\n6. **Prompt Testing and Development Tools**: LangSmith includes tools for testing prompts with versioning and collaboration features, as well as a visual interface (Studio) for designing and refining applications.\\n\\n7. **Getting Started**: Users can easily create an account, generate an API key, and start building with quickstart guides provided on the platform.\\n\\nOverall, LangSmith aims to simplify the complexities of developing AI applications while ensuring high standards of security and reliability.'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"messages\"][5].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paper titled \"Heat-bath random walks with Markov bases,\" authored by Caprice Stanley and Tobias Windisch, was published on May 27, 2016. It examines graphs on lattice points where the edges are derived from a finite set of allowances. If you need more specific details or insights from the paper, please let me know!'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})[\"messages\"][5].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
